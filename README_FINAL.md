# VeriGuard AI: Investigating AI Deception & Trustworthiness in LLM Agents

This repository accompanies the research paper submitted to the **AgentX Competition at UC Berkeley â€“ May 2025**.

---

## ğŸ§  Project Summary

**VeriGuard AI** is a modular framework designed to **detect, classify, and mitigate deceptive outputs** in Large Language Models (LLMs) across high-stakes domains such as **law, medicine, and finance**. We introduce a three-part mitigation strategy combining:

- âœ… Self-Reflection Prompting  
- âœ… Cross-Verification with external databases  
- âœ… Confidence Calibration  

---

## ğŸ“„ Paper

The full PDF paper is available here:  
[`LLM - Investigating AI Deception & Trustworthiness in LLM Agents.pdf`](./LLM%20-%20Investigating%20AI%20Deception%20&%20Trustworthiness%20in%20LLM%20Agents.pdf)

---

## ğŸ“ Repository Structure

```
LLM-Deception-Trustworthiness/
â”œâ”€â”€ README.md
â”œâ”€â”€ LLM - Investigating AI Deception & Trustworthiness in LLM Agents.pdf
â”œâ”€â”€ /data/
â”‚   â”œâ”€â”€ high_quality_prompts_sample.csv       # 500 realistic prompts + annotations
â”‚   â””â”€â”€ simulated_10000_prompts.csv           # 10,000 simulated samples (scale test)
â”œâ”€â”€ /src/
â”‚   â””â”€â”€ main.py                               # Script placeholder for evaluation framework
â”œâ”€â”€ /figures/
â”‚   â”œâ”€â”€ figure_page_4.png                     # Framework overview
â”‚   â”œâ”€â”€ figure_page_5.png                     # Deception rates
â”‚   â”œâ”€â”€ figure_page_6.png                     # Strategy effectiveness
â”‚   â””â”€â”€ figure_page_7.png                     # Combined mitigation impact
â”œâ”€â”€ /docs/                                    # Appendices, slides, or supplementary materials
```

---

## ğŸ“Š Benchmark Datasets

### âœ… High-Quality Prompt Sample
- 500 prompts across **Law, Medicine, Finance**
- Includes prompt texts, model used, deception type, mitigation strategy, and result  
â¡ï¸ [`high_quality_prompts_sample.csv`](./data/high_quality_prompts_sample.csv)

### ğŸ” Simulated Evaluation Dataset
- 10,000 prompt-level evaluations with metadata
- Optimized for testing mitigation accuracy and performance at scale  
â¡ï¸ [`simulated_10000_prompts.csv`](./data/simulated_10000_prompts.csv)

---

## ğŸ“ˆ Figures from Paper

Key visual results included in the research paper:

- `figure_page_4.png` â€” Framework overview (Self-Reflection â†’ Verification â†’ Calibration)
- `figure_page_5.png` â€” Deception rate comparison (Baseline vs. Mitigated)
- `figure_page_6.png` â€” Individual mitigation effectiveness
- `figure_page_7.png` â€” Combined strategy impact (Ablation study)

---

## ğŸ¥ Video Demo

ğŸ”— https://youtu.be/SUf-V-r1TdM

---

## ğŸ“œ License

All code and data are shared for academic, evaluation, and non-commercial research use.  
Please contact the author for permissions beyond this scope.

---

## ğŸ™‹â€â™‚ï¸ Author

BoecyÃ n Bourgade  
`VeriGuard AI â€“ UC Berkeley AgentX Track`  
contact: boecyan[at]gmail[dot]com
